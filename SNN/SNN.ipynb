{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis through Metric Learning\n",
    "\n",
    "In this project, we are utilizing the \n",
    "\n",
    "\"@inproceedings{sazzed2019sentiment, title={A Sentiment Classification in Bengali and Machine Translated English Corpus}, author={Sazzed, Salim and Jayarathna, Sampath}, booktitle={2019 IEEE 20th International Conference on Information Reuse and Integration for Data Science (IRI)}, pages={107--114}, year={2019}, organization={IEEE} }\"\n",
    "\n",
    "data to implement sentiment analysis through siamese network. \n",
    "\n",
    "There are in total 3307 negative comments and 8500 positive comments present\n",
    "\n",
    "We will implement Metric Learning Techniques to proceed with the analysis. The Siamese Neural Network architecture would help us to achieve the implementation. The network would have two parts. One for distance learning, the other for sentiment classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files needed to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from itertools import combinations\n",
    "import random\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None \n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_generator(X, y):\n",
    "    #equal number of similar and dissimilar pair geneartor\n",
    "    x1 = np.zeros((int(np.ceil(X.shape[0]/2))*2, X.shape[1],))\n",
    "    x2 = np.zeros((int(np.ceil(X.shape[0]/2))*2, X.shape[1],))\n",
    "    y1_label =  np.zeros((int(np.ceil(X.shape[0]/2))*2, 1,))\n",
    "    y2_label =  np.zeros((int(np.ceil(X.shape[0]/2))*2, 1,))\n",
    "    y_simil =  np.zeros((int(np.ceil(X.shape[0]/2))*2, 1,))\n",
    "    \n",
    "    marker_comb = list(combinations(list(range(X.shape[0])),2))\n",
    "    random.shuffle(marker_comb)\n",
    "    \n",
    "    simil_count = 0\n",
    "    disimil_count = 0\n",
    "    count = 0\n",
    "    fill_up_count = 0\n",
    "    \n",
    "    \n",
    "    while count<len(marker_comb):\n",
    "        \n",
    "        ids = marker_comb[count]\n",
    "        \n",
    "        one_val, one_label = X[ids[0]], y[ids[0]]\n",
    "        two_val, two_label = X[ids[1]], y[ids[1]]\n",
    "        \n",
    "        if one_label == two_label:\n",
    "            if simil_count<int(np.ceil(X.shape[0]/2)):\n",
    "                x1[fill_up_count] = one_val\n",
    "                x2[fill_up_count] = two_val\n",
    "                y1_label[fill_up_count] = one_label\n",
    "                y2_label[fill_up_count] = two_label\n",
    "                \n",
    "                simil_count +=1\n",
    "                y_simil[fill_up_count] = 1 #similar labels\n",
    "                fill_up_count += 1\n",
    "                \n",
    "                \n",
    "        else:\n",
    "            \n",
    "            if disimil_count<int(np.ceil(X.shape[0]/2)):\n",
    "                x1[fill_up_count] = one_val\n",
    "                x2[fill_up_count] = two_val\n",
    "                y1_label[fill_up_count] = one_label\n",
    "                y2_label[fill_up_count] = two_label\n",
    "                \n",
    "                disimil_count += 1\n",
    "                y_simil[fill_up_count] = -1 #dissimilar labels\n",
    "                fill_up_count += 1\n",
    "        count +=1\n",
    "    x1 = x1[~np.all(y1_label == 0, axis=1)]\n",
    "    x2 = x2[~np.all(y1_label == 0, axis=1)]\n",
    "    y1_label = y1_label[~np.all(y1_label == 0, axis=1)]\n",
    "    y2_label = y2_label[~np.all(y1_label == 0, axis=1)]\n",
    "    y_simil = y_simil[~np.all(y1_label == 0, axis=1)]\n",
    "    y_simil = np.array(y_simil, dtype = np.float32)\n",
    "    \n",
    "    print(count, simil_count, disimil_count)\n",
    "    return x1, x2, y1_label, y2_label, y_simil\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siamese_model(max_len, max_features,embedding_dim):\n",
    "    #Here the siamese network part is defined\n",
    "    input = tf.keras.Input(shape = (max_len,), name = 'Input')\n",
    "    x = input\n",
    "    x = tf.keras.layers.Embedding(\n",
    "            input_dim=max_features,\n",
    "            output_dim=embedding_dim,\n",
    "            # Use masking to handle the variable sequence lengths\n",
    "            mask_zero=True)(x)\n",
    "    x = tf.keras.layers.LSTM(64)(x)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "  \n",
    "    return tf.keras.Model(inputs = input, outputs = x)\n",
    "    \n",
    "\n",
    "def classification_model():\n",
    "    #Here the classification network part is defined\n",
    "    input = tf.keras.Input(shape = (64,))\n",
    "    x = input\n",
    "    x = tf.keras.layers.Dense(units = 1,\n",
    "                             name = 'Classification_output')(x) \n",
    "    return tf.keras.Model(inputs = input, outputs = x)\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    #contrastive loss\n",
    "    print(y_true.shape, y_pred.shape)\n",
    "    margin = 1\n",
    "    square_pred = tf.math.square(y_pred)\n",
    "    margin_square = tf.math.square(tf.math.maximum(margin - y_pred, 0))\n",
    "    return tf.keras.backend.mean(y_true* square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "def cross_entropy_loss_defined(y_true, y_pred):\n",
    "    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(y_true, y_pred)\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis = 1, keepdims=True)\n",
    "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "def similarity_accuracy(y_true, y_pred):\n",
    "    return tf.keras.backend.mean(tf.math.equal(y_true, tf.cast(y_pred< 0.5, y_true.dtype))) #it is less than .5 as the similar paris are 1\n",
    "\n",
    "def non_nan_average(x):\n",
    "    # Computes the average of all elements that are not NaN in a rank 1 tensor\n",
    "    nan_mask = tf.math.is_nan(x)\n",
    "    x = tf.boolean_mask(x, tf.logical_not(nan_mask))\n",
    "    return tf.keras.backend.mean(x)\n",
    "    \n",
    "\n",
    "def class_accuracy(y_true, y_pred): \n",
    "    \n",
    "    y_pred = tf.keras.activations.sigmoid(y_pred)\n",
    "    y_pred = tf.where(y_pred>0.5, 1, -1)\n",
    "    confusion_matrix = tf.math.confusion_matrix(y_true, y_pred)\n",
    "    total_instance = tf.reduce_sum(confusion_matrix, axis = 1)\n",
    "    correct_instances = tf.linalg.tensor_diag_part(confusion_matrix)\n",
    "    ratio = tf.divide(correct_instances, tf.maximum(1,total_instance))\n",
    "    uar = non_nan_average(ratio)   \n",
    "    \n",
    "    return uar\n",
    "    \n",
    "\n",
    "\n",
    "def total_model(max_len, max_features,embedding_dim):\n",
    "    siamese_network = siamese_model(max_len, max_features,embedding_dim)\n",
    "    \n",
    "    input_a = tf.keras.Input(shape = max_len)\n",
    "    input_b = tf.keras.Input(shape = max_len)\n",
    "    \n",
    "    processed_a = siamese_network(input_a)\n",
    "    processed_b = siamese_network(input_b)\n",
    "    \n",
    "    distance = tf.keras.layers.Lambda(euclidean_distance, \n",
    "                                      output_shape = eucl_dist_output_shape, \n",
    "                                      name = 'Distance' )([processed_a, processed_b])\n",
    "    \n",
    "    classification_network = classification_model()\n",
    "    \n",
    "    accuracy_a = classification_network(processed_a)\n",
    "    accuracyoutputa = tf.keras.layers.Lambda(lambda x: x, name = 'accuracyoutput_a')([accuracy_a])\n",
    "    \n",
    "    accuracy_b = classification_network(processed_b)\n",
    "    accuracyoutputb = tf.keras.layers.Lambda(lambda x: x, name = 'accuracyoutput_b')([accuracy_b])\n",
    "    \n",
    "    return tf.keras.Model(inputs = [input_a, input_b],outputs = [distance, accuracyoutputa, accuracyoutputb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_file = open('data/all_positive_8500.txt', encoding=\"utf8\")\n",
    "pos_lines = pos_file.readlines()\n",
    "pos_values = [1]*len(pos_lines)\n",
    "\n",
    "neg_file = open('data/all_negative_3307.txt', encoding=\"utf8\")\n",
    "neg_lines = neg_file.readlines()\n",
    "neg_values = [-1]*len(neg_lines)\n",
    "\n",
    "X = np.array(pos_lines + neg_lines)\n",
    "y = np.array(pos_values + neg_values)\n",
    "\n",
    "#removing whitespaces, punctuations, digits and english words from text\n",
    "converted_X =[]\n",
    "punctuation_list = ['[',',','-','_','=',':','+','$','@',\n",
    "                    '~','!',';','/','^',']','{','}','(',')','<','>','.']\n",
    "whitespace = re.compile(u\"[\\s\\u0020\\u00a0\\u1680\\u180e\\u202f\\u205f\\u3000\\u2000-\\u200a]+\", re.UNICODE)\n",
    "bangla_digits = u\"[\\u09E6\\u09E7\\u09E8\\u09E9\\u09EA\\u09EB\\u09EC\\u09ED\\u09EE\\u09EF]+\"\n",
    "english_chars = u\"[a-zA-Z0-9]\"\n",
    "punc = u\"[(),$%^&*+={}\\[\\]:\\\"|\\'\\~`<>/,¦!?½£¶¼©⅐⅑⅒⅓⅔⅕⅖⅗⅘⅙⅚⅛⅜⅝⅞⅟↉¤¿º;-]+\"\n",
    "bangla_fullstop = u\"\\u0964\"     #bangla fullstop(dari)\n",
    "punctSeq   = u\"['\\\"“”‘’]+|[.?!,…]+|[:;]+\"\n",
    "\n",
    "\n",
    "for x in X:\n",
    "#     x = re.sub(bangla_digits, \" \", x)\n",
    "#     x = re.sub(punc, \" \", x)\n",
    "#     x = re.sub(english_chars, \" \", x)\n",
    "#     x = re.sub(bangla_fullstop, \" \", x)\n",
    "#     x = re.sub(punctSeq, \" \", x)\n",
    "#     x = whitespace.sub(\" \", x).strip()\n",
    "    \n",
    "#     x = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', x, flags=re.MULTILINE)\n",
    "#     x = re.sub(r'\\<a href', ' ', x)\n",
    "#     x = re.sub(r'&amp;‘:‘ ’', '', x) \n",
    "#     x = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]। ,', ' ', x)\n",
    "#     x = re.sub(r'<br />', ' ', x)\n",
    "#     x = re.sub(r'\\'', ' ', x)\n",
    "#     x = re.sub(r\"[\\@$#%~+-\\.\\'।\\\"]\",\" \",x)\n",
    "#     x = re.sub(r\"(?m)^\\s+\", \"\", x)\n",
    "#     x = re.sub(\"[()]\",\"\",x)\n",
    "#     x = re.sub(\"[‘’]\",\"\",x)\n",
    "#     x = re.sub(\"[!]\",\"\",x)\n",
    "#     x = re.sub(\"[/]\",\"\",x)\n",
    "#     x = re.sub(\"[:]\",\"\",x)\n",
    "#     x = re.sub('\\ |\\?|\\.|\\!|\\/|\\;|\\:', ' ',x)\n",
    "#     x = x.strip(\"/\")\n",
    "    converted_X.append(x)\n",
    "converted_X = np.array(converted_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Sets and Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "\n",
      "Epoch 00001: saving model to saved_model/SNN/0/cp.ckpt\n",
      "\n",
      "Epoch 00002: saving model to saved_model/SNN/0/cp.ckpt\n",
      "\n",
      "Epoch 00003: saving model to saved_model/SNN/0/cp.ckpt\n",
      "\n",
      "Epoch 00004: saving model to saved_model/SNN/0/cp.ckpt\n",
      "\n",
      "Epoch 00005: saving model to saved_model/SNN/0/cp.ckpt\n",
      "\n",
      "Epoch 00006: saving model to saved_model/SNN/0/cp.ckpt\n",
      "\n",
      "Epoch 00007: saving model to saved_model/SNN/0/cp.ckpt\n",
      "\n",
      "Epoch 00008: saving model to saved_model/SNN/0/cp.ckpt\n",
      "\n",
      "Epoch 00009: saving model to saved_model/SNN/0/cp.ckpt\n",
      "\n",
      "Epoch 00010: saving model to saved_model/SNN/0/cp.ckpt\n",
      "\n",
      "Epoch 00011: saving model to saved_model/SNN/0/cp.ckpt\n",
      "\n",
      "Epoch 00012: saving model to saved_model/SNN/0/cp.ckpt\n",
      "\n",
      "Epoch 00013: saving model to saved_model/SNN/0/cp.ckpt\n",
      "\n",
      "Epoch 00014: saving model to saved_model/SNN/0/cp.ckpt\n",
      "\n",
      "Epoch 00015: saving model to saved_model/SNN/0/cp.ckpt\n",
      "\n",
      "Epoch 00016: saving model to saved_model/SNN/0/cp.ckpt\n",
      "\n",
      "Epoch 00017: saving model to saved_model/SNN/0/cp.ckpt\n",
      "\n",
      "Epoch 00018: saving model to saved_model/SNN/0/cp.ckpt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.98      0.85       331\n",
      "           1       0.99      0.87      0.93       850\n",
      "\n",
      "    accuracy                           0.90      1181\n",
      "   macro avg       0.87      0.93      0.89      1181\n",
      "weighted avg       0.92      0.90      0.91      1181\n",
      "\n",
      "(None, None) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "\n",
      "Epoch 00001: saving model to saved_model/SNN/1/cp.ckpt\n",
      "\n",
      "Epoch 00002: saving model to saved_model/SNN/1/cp.ckpt\n",
      "\n",
      "Epoch 00003: saving model to saved_model/SNN/1/cp.ckpt\n",
      "\n",
      "Epoch 00004: saving model to saved_model/SNN/1/cp.ckpt\n",
      "\n",
      "Epoch 00005: saving model to saved_model/SNN/1/cp.ckpt\n",
      "\n",
      "Epoch 00006: saving model to saved_model/SNN/1/cp.ckpt\n",
      "\n",
      "Epoch 00007: saving model to saved_model/SNN/1/cp.ckpt\n",
      "\n",
      "Epoch 00008: saving model to saved_model/SNN/1/cp.ckpt\n",
      "\n",
      "Epoch 00009: saving model to saved_model/SNN/1/cp.ckpt\n",
      "\n",
      "Epoch 00010: saving model to saved_model/SNN/1/cp.ckpt\n",
      "\n",
      "Epoch 00011: saving model to saved_model/SNN/1/cp.ckpt\n",
      "\n",
      "Epoch 00012: saving model to saved_model/SNN/1/cp.ckpt\n",
      "\n",
      "Epoch 00013: saving model to saved_model/SNN/1/cp.ckpt\n",
      "\n",
      "Epoch 00014: saving model to saved_model/SNN/1/cp.ckpt\n",
      "\n",
      "Epoch 00015: saving model to saved_model/SNN/1/cp.ckpt\n",
      "\n",
      "Epoch 00016: saving model to saved_model/SNN/1/cp.ckpt\n",
      "\n",
      "Epoch 00017: saving model to saved_model/SNN/1/cp.ckpt\n",
      "\n",
      "Epoch 00018: saving model to saved_model/SNN/1/cp.ckpt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.95      0.84       331\n",
      "           1       0.98      0.87      0.92       850\n",
      "\n",
      "    accuracy                           0.90      1181\n",
      "   macro avg       0.86      0.91      0.88      1181\n",
      "weighted avg       0.91      0.90      0.90      1181\n",
      "\n",
      "(None, None) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "\n",
      "Epoch 00001: saving model to saved_model/SNN/2/cp.ckpt\n",
      "\n",
      "Epoch 00002: saving model to saved_model/SNN/2/cp.ckpt\n",
      "\n",
      "Epoch 00003: saving model to saved_model/SNN/2/cp.ckpt\n",
      "\n",
      "Epoch 00004: saving model to saved_model/SNN/2/cp.ckpt\n",
      "\n",
      "Epoch 00005: saving model to saved_model/SNN/2/cp.ckpt\n",
      "\n",
      "Epoch 00006: saving model to saved_model/SNN/2/cp.ckpt\n",
      "\n",
      "Epoch 00007: saving model to saved_model/SNN/2/cp.ckpt\n",
      "\n",
      "Epoch 00008: saving model to saved_model/SNN/2/cp.ckpt\n",
      "\n",
      "Epoch 00009: saving model to saved_model/SNN/2/cp.ckpt\n",
      "\n",
      "Epoch 00010: saving model to saved_model/SNN/2/cp.ckpt\n",
      "\n",
      "Epoch 00011: saving model to saved_model/SNN/2/cp.ckpt\n",
      "\n",
      "Epoch 00012: saving model to saved_model/SNN/2/cp.ckpt\n",
      "\n",
      "Epoch 00013: saving model to saved_model/SNN/2/cp.ckpt\n",
      "\n",
      "Epoch 00014: saving model to saved_model/SNN/2/cp.ckpt\n",
      "\n",
      "Epoch 00015: saving model to saved_model/SNN/2/cp.ckpt\n",
      "\n",
      "Epoch 00016: saving model to saved_model/SNN/2/cp.ckpt\n",
      "\n",
      "Epoch 00017: saving model to saved_model/SNN/2/cp.ckpt\n",
      "\n",
      "Epoch 00018: saving model to saved_model/SNN/2/cp.ckpt\n",
      "\n",
      "Epoch 00019: saving model to saved_model/SNN/2/cp.ckpt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.97      0.87       331\n",
      "           1       0.99      0.90      0.94       850\n",
      "\n",
      "    accuracy                           0.92      1181\n",
      "   macro avg       0.89      0.93      0.90      1181\n",
      "weighted avg       0.93      0.92      0.92      1181\n",
      "\n",
      "(None, None) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "\n",
      "Epoch 00001: saving model to saved_model/SNN/3/cp.ckpt\n",
      "\n",
      "Epoch 00002: saving model to saved_model/SNN/3/cp.ckpt\n",
      "\n",
      "Epoch 00003: saving model to saved_model/SNN/3/cp.ckpt\n",
      "\n",
      "Epoch 00004: saving model to saved_model/SNN/3/cp.ckpt\n",
      "\n",
      "Epoch 00005: saving model to saved_model/SNN/3/cp.ckpt\n",
      "\n",
      "Epoch 00006: saving model to saved_model/SNN/3/cp.ckpt\n",
      "\n",
      "Epoch 00007: saving model to saved_model/SNN/3/cp.ckpt\n",
      "\n",
      "Epoch 00008: saving model to saved_model/SNN/3/cp.ckpt\n",
      "\n",
      "Epoch 00009: saving model to saved_model/SNN/3/cp.ckpt\n",
      "\n",
      "Epoch 00010: saving model to saved_model/SNN/3/cp.ckpt\n",
      "\n",
      "Epoch 00011: saving model to saved_model/SNN/3/cp.ckpt\n",
      "\n",
      "Epoch 00012: saving model to saved_model/SNN/3/cp.ckpt\n",
      "\n",
      "Epoch 00013: saving model to saved_model/SNN/3/cp.ckpt\n",
      "\n",
      "Epoch 00014: saving model to saved_model/SNN/3/cp.ckpt\n",
      "\n",
      "Epoch 00015: saving model to saved_model/SNN/3/cp.ckpt\n",
      "\n",
      "Epoch 00016: saving model to saved_model/SNN/3/cp.ckpt\n",
      "\n",
      "Epoch 00017: saving model to saved_model/SNN/3/cp.ckpt\n",
      "\n",
      "Epoch 00018: saving model to saved_model/SNN/3/cp.ckpt\n",
      "\n",
      "Epoch 00019: saving model to saved_model/SNN/3/cp.ckpt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.89      0.83       331\n",
      "           1       0.95      0.90      0.93       850\n",
      "\n",
      "    accuracy                           0.90      1181\n",
      "   macro avg       0.87      0.90      0.88      1181\n",
      "weighted avg       0.91      0.90      0.90      1181\n",
      "\n",
      "(None, None) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "\n",
      "Epoch 00001: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00002: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00003: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00004: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00005: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00006: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00007: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00008: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00009: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00010: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00011: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00012: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00013: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00014: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00015: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00016: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00017: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00018: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00019: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00020: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00021: saving model to saved_model/SNN/4/cp.ckpt\n",
      "\n",
      "Epoch 00022: saving model to saved_model/SNN/4/cp.ckpt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.77      0.87      0.82       331\n",
      "           1       0.95      0.90      0.92       850\n",
      "\n",
      "    accuracy                           0.89      1181\n",
      "   macro avg       0.86      0.88      0.87      1181\n",
      "weighted avg       0.90      0.89      0.89      1181\n",
      "\n",
      "(None, None) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "\n",
      "Epoch 00001: saving model to saved_model/SNN/5/cp.ckpt\n",
      "\n",
      "Epoch 00002: saving model to saved_model/SNN/5/cp.ckpt\n",
      "\n",
      "Epoch 00003: saving model to saved_model/SNN/5/cp.ckpt\n",
      "\n",
      "Epoch 00004: saving model to saved_model/SNN/5/cp.ckpt\n",
      "\n",
      "Epoch 00005: saving model to saved_model/SNN/5/cp.ckpt\n",
      "\n",
      "Epoch 00006: saving model to saved_model/SNN/5/cp.ckpt\n",
      "\n",
      "Epoch 00007: saving model to saved_model/SNN/5/cp.ckpt\n",
      "\n",
      "Epoch 00008: saving model to saved_model/SNN/5/cp.ckpt\n",
      "\n",
      "Epoch 00009: saving model to saved_model/SNN/5/cp.ckpt\n",
      "\n",
      "Epoch 00010: saving model to saved_model/SNN/5/cp.ckpt\n",
      "\n",
      "Epoch 00011: saving model to saved_model/SNN/5/cp.ckpt\n",
      "\n",
      "Epoch 00012: saving model to saved_model/SNN/5/cp.ckpt\n",
      "\n",
      "Epoch 00013: saving model to saved_model/SNN/5/cp.ckpt\n",
      "\n",
      "Epoch 00014: saving model to saved_model/SNN/5/cp.ckpt\n",
      "\n",
      "Epoch 00015: saving model to saved_model/SNN/5/cp.ckpt\n",
      "\n",
      "Epoch 00016: saving model to saved_model/SNN/5/cp.ckpt\n",
      "\n",
      "Epoch 00017: saving model to saved_model/SNN/5/cp.ckpt\n",
      "\n",
      "Epoch 00018: saving model to saved_model/SNN/5/cp.ckpt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.85      0.79       331\n",
      "           1       0.94      0.88      0.91       850\n",
      "\n",
      "    accuracy                           0.87      1181\n",
      "   macro avg       0.84      0.87      0.85      1181\n",
      "weighted avg       0.88      0.87      0.88      1181\n",
      "\n",
      "(None, None) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "\n",
      "Epoch 00001: saving model to saved_model/SNN/6/cp.ckpt\n",
      "\n",
      "Epoch 00002: saving model to saved_model/SNN/6/cp.ckpt\n",
      "\n",
      "Epoch 00003: saving model to saved_model/SNN/6/cp.ckpt\n",
      "\n",
      "Epoch 00004: saving model to saved_model/SNN/6/cp.ckpt\n",
      "\n",
      "Epoch 00005: saving model to saved_model/SNN/6/cp.ckpt\n",
      "\n",
      "Epoch 00006: saving model to saved_model/SNN/6/cp.ckpt\n",
      "\n",
      "Epoch 00007: saving model to saved_model/SNN/6/cp.ckpt\n",
      "\n",
      "Epoch 00008: saving model to saved_model/SNN/6/cp.ckpt\n",
      "\n",
      "Epoch 00009: saving model to saved_model/SNN/6/cp.ckpt\n",
      "\n",
      "Epoch 00010: saving model to saved_model/SNN/6/cp.ckpt\n",
      "\n",
      "Epoch 00011: saving model to saved_model/SNN/6/cp.ckpt\n",
      "\n",
      "Epoch 00012: saving model to saved_model/SNN/6/cp.ckpt\n",
      "\n",
      "Epoch 00013: saving model to saved_model/SNN/6/cp.ckpt\n",
      "\n",
      "Epoch 00014: saving model to saved_model/SNN/6/cp.ckpt\n",
      "\n",
      "Epoch 00015: saving model to saved_model/SNN/6/cp.ckpt\n",
      "\n",
      "Epoch 00016: saving model to saved_model/SNN/6/cp.ckpt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.63      0.95      0.76       331\n",
      "           1       0.97      0.79      0.87       850\n",
      "\n",
      "    accuracy                           0.83      1181\n",
      "   macro avg       0.80      0.87      0.82      1181\n",
      "weighted avg       0.88      0.83      0.84      1181\n",
      "\n",
      "(None, None) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "\n",
      "Epoch 00001: saving model to saved_model/SNN/7/cp.ckpt\n",
      "\n",
      "Epoch 00002: saving model to saved_model/SNN/7/cp.ckpt\n",
      "\n",
      "Epoch 00003: saving model to saved_model/SNN/7/cp.ckpt\n",
      "\n",
      "Epoch 00004: saving model to saved_model/SNN/7/cp.ckpt\n",
      "\n",
      "Epoch 00005: saving model to saved_model/SNN/7/cp.ckpt\n",
      "\n",
      "Epoch 00006: saving model to saved_model/SNN/7/cp.ckpt\n",
      "\n",
      "Epoch 00007: saving model to saved_model/SNN/7/cp.ckpt\n",
      "\n",
      "Epoch 00008: saving model to saved_model/SNN/7/cp.ckpt\n",
      "\n",
      "Epoch 00009: saving model to saved_model/SNN/7/cp.ckpt\n",
      "\n",
      "Epoch 00010: saving model to saved_model/SNN/7/cp.ckpt\n",
      "\n",
      "Epoch 00011: saving model to saved_model/SNN/7/cp.ckpt\n",
      "\n",
      "Epoch 00012: saving model to saved_model/SNN/7/cp.ckpt\n",
      "\n",
      "Epoch 00013: saving model to saved_model/SNN/7/cp.ckpt\n",
      "\n",
      "Epoch 00014: saving model to saved_model/SNN/7/cp.ckpt\n",
      "\n",
      "Epoch 00015: saving model to saved_model/SNN/7/cp.ckpt\n",
      "\n",
      "Epoch 00016: saving model to saved_model/SNN/7/cp.ckpt\n",
      "\n",
      "Epoch 00017: saving model to saved_model/SNN/7/cp.ckpt\n",
      "\n",
      "Epoch 00018: saving model to saved_model/SNN/7/cp.ckpt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.75      0.98      0.85       330\n",
      "           1       0.99      0.88      0.93       850\n",
      "\n",
      "    accuracy                           0.90      1180\n",
      "   macro avg       0.87      0.93      0.89      1180\n",
      "weighted avg       0.92      0.90      0.91      1180\n",
      "\n",
      "(None, None) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "\n",
      "Epoch 00001: saving model to saved_model/SNN/8/cp.ckpt\n",
      "\n",
      "Epoch 00002: saving model to saved_model/SNN/8/cp.ckpt\n",
      "\n",
      "Epoch 00003: saving model to saved_model/SNN/8/cp.ckpt\n",
      "\n",
      "Epoch 00004: saving model to saved_model/SNN/8/cp.ckpt\n",
      "\n",
      "Epoch 00005: saving model to saved_model/SNN/8/cp.ckpt\n",
      "\n",
      "Epoch 00006: saving model to saved_model/SNN/8/cp.ckpt\n",
      "\n",
      "Epoch 00007: saving model to saved_model/SNN/8/cp.ckpt\n",
      "\n",
      "Epoch 00008: saving model to saved_model/SNN/8/cp.ckpt\n",
      "\n",
      "Epoch 00009: saving model to saved_model/SNN/8/cp.ckpt\n",
      "\n",
      "Epoch 00010: saving model to saved_model/SNN/8/cp.ckpt\n",
      "\n",
      "Epoch 00011: saving model to saved_model/SNN/8/cp.ckpt\n",
      "\n",
      "Epoch 00012: saving model to saved_model/SNN/8/cp.ckpt\n",
      "\n",
      "Epoch 00013: saving model to saved_model/SNN/8/cp.ckpt\n",
      "\n",
      "Epoch 00014: saving model to saved_model/SNN/8/cp.ckpt\n",
      "\n",
      "Epoch 00015: saving model to saved_model/SNN/8/cp.ckpt\n",
      "\n",
      "Epoch 00016: saving model to saved_model/SNN/8/cp.ckpt\n",
      "\n",
      "Epoch 00017: saving model to saved_model/SNN/8/cp.ckpt\n",
      "\n",
      "Epoch 00018: saving model to saved_model/SNN/8/cp.ckpt\n",
      "\n",
      "Epoch 00019: saving model to saved_model/SNN/8/cp.ckpt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.96      0.83       330\n",
      "           1       0.98      0.86      0.92       850\n",
      "\n",
      "    accuracy                           0.89      1180\n",
      "   macro avg       0.86      0.91      0.87      1180\n",
      "weighted avg       0.91      0.89      0.89      1180\n",
      "\n",
      "(None, None) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "(None, 1) (None, 1)\n",
      "\n",
      "Epoch 00001: saving model to saved_model/SNN/9/cp.ckpt\n",
      "\n",
      "Epoch 00002: saving model to saved_model/SNN/9/cp.ckpt\n",
      "\n",
      "Epoch 00003: saving model to saved_model/SNN/9/cp.ckpt\n",
      "\n",
      "Epoch 00004: saving model to saved_model/SNN/9/cp.ckpt\n",
      "\n",
      "Epoch 00005: saving model to saved_model/SNN/9/cp.ckpt\n",
      "\n",
      "Epoch 00006: saving model to saved_model/SNN/9/cp.ckpt\n",
      "\n",
      "Epoch 00007: saving model to saved_model/SNN/9/cp.ckpt\n",
      "\n",
      "Epoch 00008: saving model to saved_model/SNN/9/cp.ckpt\n",
      "\n",
      "Epoch 00009: saving model to saved_model/SNN/9/cp.ckpt\n",
      "\n",
      "Epoch 00010: saving model to saved_model/SNN/9/cp.ckpt\n",
      "\n",
      "Epoch 00011: saving model to saved_model/SNN/9/cp.ckpt\n",
      "\n",
      "Epoch 00012: saving model to saved_model/SNN/9/cp.ckpt\n",
      "\n",
      "Epoch 00013: saving model to saved_model/SNN/9/cp.ckpt\n",
      "\n",
      "Epoch 00014: saving model to saved_model/SNN/9/cp.ckpt\n",
      "\n",
      "Epoch 00015: saving model to saved_model/SNN/9/cp.ckpt\n",
      "\n",
      "Epoch 00016: saving model to saved_model/SNN/9/cp.ckpt\n",
      "\n",
      "Epoch 00017: saving model to saved_model/SNN/9/cp.ckpt\n",
      "\n",
      "Epoch 00018: saving model to saved_model/SNN/9/cp.ckpt\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.53      0.95      0.68       330\n",
      "           1       0.97      0.67      0.80       850\n",
      "\n",
      "    accuracy                           0.75      1180\n",
      "   macro avg       0.75      0.81      0.74      1180\n",
      "weighted avg       0.85      0.75      0.76      1180\n",
      "\n",
      "{'precision': [0.8704078988766124, 0.8617863358221524, 0.8860144499679383, 0.8690471464019851, 0.8583848544487075, 0.838525855838097, 0.8043628237180999, 0.8708490753628952, 0.8566143829535365, 0.7508474576271187], 'recall': [0.9268189088324151, 0.9123014039452639, 0.932207215212369, 0.8964617025057757, 0.8844570819264261, 0.8662360049760085, 0.8669273147325396, 0.9255258467023173, 0.9124064171122994, 0.811301247771836], 'f1-score': [0.8888315919145784, 0.8792146693587763, 0.9034319222502569, 0.8808025755771784, 0.8695848688349876, 0.8500938356415282, 0.8154850581388009, 0.8892215864733726, 0.8743656859436988, 0.7381340579710144]} {'precision': [0.9238284118183931, 0.9132492880571815, 0.9298607932993456, 0.9064218026108168, 0.8972027930161791, 0.882055133632093, 0.878839712895249, 0.9230749786829608, 0.912693555911136, 0.8479459925308819], 'recall': [0.9026248941574937, 0.8950042337002541, 0.9170194750211685, 0.9000846740050804, 0.890770533446232, 0.8738357324301439, 0.8323454699407282, 0.9033898305084745, 0.8898305084745762, 0.7508474576271187], 'f1-score': [0.906040062741677, 0.8984062007246472, 0.9193505224491353, 0.9018708052278757, 0.892684364493046, 0.8763109514570422, 0.8399964131113506, 0.906680086232266, 0.8937901007167816, 0.7635608572832226]}\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10, random_state = 42)\n",
    "fold_count = 0\n",
    "max_features = 2500\n",
    "embedding_dim = 64\n",
    "batch_size = 256\n",
    "macro_avg = {'precision':[],'recall':[],'f1-score':[]}\n",
    "weighted_avg =  {'precision':[],'recall':[],'f1-score':[]}\n",
    "metrics = ['precision', 'recall', 'f1-score']\n",
    "epochs = 500\n",
    "read_from_store_data = 0\n",
    "read_from_stored_model = 0\n",
    "maxlen = 250\n",
    "\n",
    "\n",
    "if read_from_store_data:\n",
    "    \n",
    "    if read_from_stored_model:\n",
    "        \n",
    "        for fc in range(10):\n",
    "            with open('train_eval_test_data_'+str(fold_count)+'.pkl','rb') as f:\n",
    "                X1_train, X2_train, y1_label_train, y2_label_train, y_simil_train, X1_eval, X2_eval, y1_label_eval, y2_label_eval, y_simil_eval, X_test_tokenized_padded, y_test = pickle.load(f)\n",
    "            final_model = total_model(maxlen, max_features,embedding_dim)\n",
    "            checkpoint_path = \"saved_model/SNN/\"+str(fold_count)+\"/cp.ckpt\"\n",
    "            checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "            fold_count += 1\n",
    "            latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "            final_model.load_weights(latest)\n",
    "            predictions =  tf.keras.activations.sigmoid(final_model.predict([X_test_tokenized_padded, X_test_tokenized_padded])[-1])\n",
    "\n",
    "            predictions = np.where(predictions>0.5, 1, -1)\n",
    "            print(classification_report(y_test, predictions))\n",
    "            cl = classification_report(y_test, predictions, output_dict =True)\n",
    "            \n",
    "    else:\n",
    "        for fc in range(10):\n",
    "            with open('train_eval_test_data_'+str(fold_count)+'.pkl','rb') as f:\n",
    "                X1_train, X2_train, y1_label_train, y2_label_train, y_simil_train, X1_eval, X2_eval, y1_label_eval, y2_label_eval, y_simil_eval, X_test_tokenized_padded, y_test = pickle.load(f)\n",
    "            final_model = total_model(maxlen, max_features,embedding_dim)\n",
    "            losses = {'Distance': contrastive_loss, 'accuracyoutput_a': cross_entropy_loss_defined, 'accuracyoutput_b': cross_entropy_loss_defined}\n",
    "        #     weights = {'Distance': distance_weight, 'accuracyoutput':class_weight}\n",
    "            metrices = {'Distance':similarity_accuracy, 'accuracyoutput_a': class_accuracy, 'accuracyoutput_b': class_accuracy}\n",
    "            final_model.compile(optimizer = tf.keras.optimizers.Adam(1e-4), loss = losses)#, metrics = metrices)\n",
    "    #         print(final_model.summary())\n",
    "\n",
    "            checkpoint_path = \"saved_model/SNN/\"+str(fold_count)+\"/cp.ckpt\"\n",
    "            checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "            # Create a callback that saves the model's weights\n",
    "            cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                             save_weights_only=True,\n",
    "                                                             verbose=1)\n",
    "\n",
    "            es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=3)\n",
    "            final_model.fit(x = [X1_train, X2_train], y = [y_simil_train, y1_label_train, y2_label_train], batch_size=batch_size, epochs= epochs,\n",
    "                           validation_data = ([X1_eval, X2_eval], [y_simil_eval, y1_label_eval, y2_label_eval]), verbose = 0, callbacks=[es, cp_callback])\n",
    "            predictions =  tf.keras.activations.sigmoid(final_model.predict([X_test_tokenized_padded, X_test_tokenized_padded])[-1])\n",
    "\n",
    "            predictions = np.where(predictions>0.5, 1, -1)\n",
    "            print(classification_report(y_test, predictions))\n",
    "            cl = classification_report(y_test, predictions, output_dict =True)\n",
    "            for t in metrics:\n",
    "                macro_avg[t].append(cl['macro avg'][t])\n",
    "                weighted_avg[t].append(cl['weighted avg'][t])\n",
    "\n",
    "\n",
    "            tf.keras.backend.clear_session()\n",
    "            fold_count += 1\n",
    "else:\n",
    "\n",
    "    for train_index, test_index in skf.split(converted_X, y):\n",
    "\n",
    "        X_train, X_test = converted_X[train_index], converted_X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "        X_train, X_eval, y_train, y_eval = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42) #approximate train, test, eval size (8500,) (1181,) (2126,)\n",
    "\n",
    "        #Data processing: Tokenization\n",
    "        tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_features)\n",
    "        tokenizer.fit_on_texts(X_train) #fitting the tokenizer on the train data\n",
    "        X_train_tokenized_padded = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen = maxlen)\n",
    "        X_test_tokenized_padded = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen = maxlen)\n",
    "        X_eval_tokenized_padded = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(X_eval), maxlen = maxlen)\n",
    "\n",
    "        #pair making\n",
    "        X1_train, X2_train, y1_label_train, y2_label_train, y_simil_train = pair_generator(X_train_tokenized_padded, y_train)\n",
    "        X1_eval, X2_eval, y1_label_eval, y2_label_eval, y_simil_eval = pair_generator(X_eval_tokenized_padded, y_eval)\n",
    "\n",
    "        #make similar labels 1 and dissimilar labels 0\n",
    "        y_simil_train = np.where(y_simil_train == -1, 0, y_simil_train)\n",
    "        y_simil_eval = np.where(y_simil_eval == -1, 0, y_simil_eval)\n",
    "\n",
    "        with open('train_eval_test_data_'+str(fold_count)+'.pkl','wb') as f:\n",
    "            pickle.dump([X1_train, X2_train, y1_label_train, y2_label_train, y_simil_train, X1_eval, X2_eval, y1_label_eval, y2_label_eval, y_simil_eval, X_test_tokenized_padded, y_test],f)\n",
    "\n",
    "        final_model = total_model(maxlen, max_features,embedding_dim)\n",
    "        losses = {'Distance': contrastive_loss, 'accuracyoutput_a': cross_entropy_loss_defined, 'accuracyoutput_b': cross_entropy_loss_defined}\n",
    "    #     weights = {'Distance': distance_weight, 'accuracyoutput':class_weight}\n",
    "        metrices = {'Distance':similarity_accuracy, 'accuracyoutput_a': class_accuracy, 'accuracyoutput_b': class_accuracy}\n",
    "        final_model.compile(optimizer = tf.keras.optimizers.Adam(1e-4), loss = losses)#, metrics = metrices)\n",
    "        print(final_model.summary())\n",
    "\n",
    "        checkpoint_path = \"saved_model/SNN/\"+str(fold_count)+\"/cp.ckpt\"\n",
    "        checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "        # Create a callback that saves the model's weights\n",
    "        cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                         save_weights_only=True,\n",
    "                                                         verbose=1)\n",
    "\n",
    "        es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=3)\n",
    "        final_model.fit(x = [X1_train, X2_train], y = [y_simil_train, y1_label_train, y2_label_train], batch_size=batch_size, epochs= epochs,\n",
    "                       validation_data = ([X1_eval, X2_eval], [y_simil_eval, y1_label_eval, y2_label_eval]), verbose = 1, callbacks=[es, cp_callback])\n",
    "        predictions =  tf.keras.activations.sigmoid(final_model.predict([X_test_tokenized_padded, X_test_tokenized_padded])[-1])\n",
    "        \n",
    "        predictions = np.where(predictions>0.5, 1, -1)\n",
    "        print('For fold: ', fold_count+1)\n",
    "        print(classification_report(y_test, predictions))\n",
    "        cl = classification_report(y_test, predictions, output_dict =True)\n",
    "        for t in metrics:\n",
    "            macro_avg[t].append(cl['macro avg'][t])\n",
    "            weighted_avg[t].append(cl['weighted avg'][t])\n",
    "\n",
    "\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        fold_count += 1\n",
    "    \n",
    "print(macro_avg, weighted_avg)\n",
    "with open('evaluation_metrics.pkl','wb') as f:\n",
    "            pickle.dump([macro_avg, weighted_avg],f)    \n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with cleaning: {'precision': [0.8737148064353946, 0.8672166472679228, 0.8801921836142796, 0.8715060122215652, 0.8675550968368648, 0.8433567506735327, 0.8253182651850254, 0.8826926635283934, 0.8652818769380207, 0.7486556242473364], 'recall': [0.9227154789408211, 0.9149084769859606, 0.9314448196196907, 0.9019157632841657, 0.887318286831349, 0.8578549848942598, 0.8858308157099697, 0.9350267379679145, 0.9182887700534759, 0.8084313725490195], 'f1-score': [0.8913374861675805, 0.884401627160035, 0.8984086021505377, 0.8843006114011795, 0.8764491616498806, 0.8500299199120493, 0.84018010356836, 0.901229779577819, 0.883228436844397, 0.7394433901345427]} {'precision': [0.9217439407426706, 0.9158163791100448, 0.9282289641448055, 0.9098687194062373, 0.9016130318285529, 0.8797409667898461, 0.8922219540538695, 0.9309129570633766, 0.9176357429746849, 0.8433397494701], 'recall': [0.9060118543607113, 0.9000846740050804, 0.9119390347163421, 0.9026248941574937, 0.8975444538526672, 0.8763759525825572, 0.8569009314140559, 0.9144067796610169, 0.8983050847457628, 0.7533898305084745], 'f1-score': [0.9088858665644349, 0.9031131244303306, 0.9147016288365064, 0.9045352981044286, 0.8988845236442377, 0.8776533359847637, 0.8628976681021718, 0.9171277843185681, 0.9017186654026758, 0.7660080384658414]}\n",
    "\n",
    "without cleaning: {'precision': [0.8704078988766124, 0.8617863358221524, 0.8860144499679383, 0.8690471464019851, 0.8583848544487075, 0.838525855838097, 0.8043628237180999, 0.8708490753628952, 0.8566143829535365, 0.7508474576271187], 'recall': [0.9268189088324151, 0.9123014039452639, 0.932207215212369, 0.8964617025057757, 0.8844570819264261, 0.8662360049760085, 0.8669273147325396, 0.9255258467023173, 0.9124064171122994, 0.811301247771836], 'f1-score': [0.8888315919145784, 0.8792146693587763, 0.9034319222502569, 0.8808025755771784, 0.8695848688349876, 0.8500938356415282, 0.8154850581388009, 0.8892215864733726, 0.8743656859436988, 0.7381340579710144]} {'precision': [0.9238284118183931, 0.9132492880571815, 0.9298607932993456, 0.9064218026108168, 0.8972027930161791, 0.882055133632093, 0.878839712895249, 0.9230749786829608, 0.912693555911136, 0.8479459925308819], 'recall': [0.9026248941574937, 0.8950042337002541, 0.9170194750211685, 0.9000846740050804, 0.890770533446232, 0.8738357324301439, 0.8323454699407282, 0.9033898305084745, 0.8898305084745762, 0.7508474576271187], 'f1-score': [0.906040062741677, 0.8984062007246472, 0.9193505224491353, 0.9018708052278757, 0.892684364493046, 0.8763109514570422, 0.8399964131113506, 0.906680086232266, 0.8937901007167816, 0.7635608572832226]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
